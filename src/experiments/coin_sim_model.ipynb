{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coins similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "%run ../common/datasets.ipynb\n",
    "%run ../common/visualisation.ipynb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinAugmentation:\n",
    "    _params = {\n",
    "        'smooth'    : .8,\n",
    "        'angle'     : 90,\n",
    "        'brightness': .25,\n",
    "        'contrast'  : [.5, 1.5],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, cache_size=42):\n",
    "        self.cache = dict()\n",
    "        self.cache_size = cache_size\n",
    "        \n",
    "    def augment(im, use_cache=True, rate=1):\n",
    "        shape = im.shape\n",
    "        w = shape[1]\n",
    "        h = shape[0]\n",
    "        if use_cache:\n",
    "            hc = hash(im.tostring())\n",
    "            cached = aug_cache.get(hc, [])\n",
    "            if len(cached)>=aug_cache_size:\n",
    "                return np.copy(cached[np.random.randint(aug_cache_size)])\n",
    "\n",
    "        im = np.copy(im)\n",
    "\n",
    "        # smooth\n",
    "        p = augment_params['smooth']\n",
    "        k = p*np.random.random(1)**2 * rate\n",
    "        if k > 0.1:\n",
    "            kernel = np.ones([5,5],np.float32)/25\n",
    "            old= np.copy(im)\n",
    "            im = cv2.filter2D(im,-1,kernel)\n",
    "            im = np.reshape(im, shape)\n",
    "            im = k*im + (1-k)*old\n",
    "\n",
    "        # angle\n",
    "        p = augment_params['angle']\n",
    "        k = np.random.uniform(-p, p) * rate\n",
    "        c = np.mean(im[:10,:10])\n",
    "        im[0,:]   = c\n",
    "        im[h-1,:] = c\n",
    "        im[:,0]   = c\n",
    "        im[:,w-1] = c\n",
    "        im = rotate(im, k, reshape=False, mode='nearest')\n",
    "\n",
    "        # brightness\n",
    "        p = augment_params['brightness']\n",
    "        k = np.random.uniform(1-p, 1+p) * rate\n",
    "        im = im * k\n",
    "        im = np.minimum(im,1)\n",
    "        im = np.maximum(im,0)\n",
    "\n",
    "        # contrast\n",
    "        p = augment_params['contrast']\n",
    "        k = rate*np.random.uniform(*p) + (1-rate)\n",
    "        im = np.power(im, k)\n",
    "\n",
    "        # bounding\n",
    "        assert np.all(im<=1)\n",
    "        assert np.all(im>=0)\n",
    "\n",
    "        # cache\n",
    "        if use_cache:\n",
    "            cached.append(im)\n",
    "            aug_cache[hc] = cached\n",
    "        return im    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinSimModel:\n",
    "\n",
    "    # ============================================================================\n",
    "    # data\n",
    "    image_shape = [128, 128, 1]\n",
    "    def load_coins_dataset(ndata, path):\n",
    "        return load_image_dataset(image_shape, path, ndata)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    # ============================================================================\n",
    "    # Batching\n",
    "    def get_next_batch(bs):\n",
    "        idx = np.random.choice(np.arange(len(train_images)), bs)\n",
    "        img1 = np.copy(train_images[idx])\n",
    "\n",
    "        per = np.arange(bs)\n",
    "        per = np.roll(per, shift=1+np.random.randint(bs-1))\n",
    "\n",
    "        img1 = np.reshape(img1, [-1,]+image_shape)\n",
    "        img2 = img1[per]\n",
    "        true = np.zeros([bs,2])\n",
    "        same = np.random.randint(2, size=bs)\n",
    "\n",
    "        for i in range(bs):\n",
    "            true[i,same[i]] = 1.\n",
    "            if same[i]:\n",
    "                img2[i] = augment(img1[i])\n",
    "                img1[i] = augment(img1[i])\n",
    "            else:\n",
    "                img1[i] = augment(img1[i])\n",
    "                img2[i] = augment(img2[i])\n",
    "\n",
    "        return img1, img2, true\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # ============================================================================\n",
    "    # Architecture\n",
    "    def conv2d_maxpool(inputs, filters, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu):\n",
    "        l = tf.layers.conv2d(\n",
    "            inputs=inputs,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            activation=tf.nn.relu)\n",
    "        return tf.layers.max_pooling2d(l, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    def SimilarityNet(image1, image2):\n",
    "        l = tf.concat([image1, image2], axis=1)\n",
    "        l = conv2d_maxpool(l, 16)\n",
    "        l = conv2d_maxpool(l, 32)\n",
    "        l = conv2d_maxpool(l, 64)\n",
    "        l = conv2d_maxpool(l, 128)\n",
    "        l = tf.contrib.layers.flatten(l)\n",
    "        l = tf.layers.dense(l, units=500, activation=tf.nn.relu)\n",
    "        l = tf.layers.dense(l, units=2)\n",
    "        logits = l\n",
    "        pred   = tf.nn.softmax(logits)\n",
    "\n",
    "        return logits, pred\n",
    "\n",
    "    def sim_loss(true, pred):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=true, logits=pred))\n",
    "\n",
    "    # ============================================================================\n",
    "    # Build\n",
    "    def build():\n",
    "        tf.reset_default_graph()\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            with tf.name_scope('similarity'):\n",
    "                with tf.device('/gpu:0'):\n",
    "                    image1_pl = tf.placeholder(dtype=tf.float32, shape=[None,]+image_shape, name='image1')\n",
    "                    image2_pl = tf.placeholder(dtype=tf.float32, shape=[None,]+image_shape, name='image2')\n",
    "                    true_pl   = tf.placeholder(dtype=tf.float32, shape=[None, 2], name='true')\n",
    "                    lr_pl     = tf.placeholder(dtype=tf.float32, name='lr')\n",
    "                    logits_op, pred_op = SimilarityNet(image1_pl, image2_pl)\n",
    "                    loss_op   = sim_loss(true_pl, logits_op)\n",
    "                    train_op  = tf.train.AdamOptimizer(lr_pl).minimize(loss_op)\n",
    "                    init_op   = tf.global_variables_initializer()\n",
    "\n",
    "    # ============================================================================\n",
    "    # Train\n",
    "    learning_rate = 1e-4\n",
    "    batch_size    = 256\n",
    "\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    sess = tf.Session(graph=graph)\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    def train(step_num, log_every=1, mean_win = 30):\n",
    "        try:\n",
    "            losses   = []\n",
    "            for step in range(step_num):\n",
    "                img1, img2, true = get_next_batch(batch_size)\n",
    "                _, loss = sess.run([train_op, loss_op], feed_dict={\n",
    "                    image1_pl: img1,\n",
    "                    image2_pl: img2,\n",
    "                    true_pl  : true,\n",
    "                    lr_pl    : learning_rate\n",
    "                })\n",
    "                losses.append(loss)\n",
    "                if step % log_every == log_every-1:\n",
    "                    show_losses(losses, step, step_num, mean_win)\n",
    "                if np.mean(losses[-mean_win:]) < .1:\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        show_losses(losses, step, step_num, mean_win)\n",
    "\n",
    "        \n",
    "    # ============================================================================\n",
    "    # Eval similarity\n",
    "    def get_similarity(img1, img2, use_aug):\n",
    "        img1 = np.copy(np.reshape(img1, [-1,]+image_shape))\n",
    "        img2 = np.copy(np.reshape(img2, [-1,]+image_shape))\n",
    "        if use_aug:\n",
    "            for i in range(len(img2)):\n",
    "                img1[i] = augment(img1[i], use_cache = False)\n",
    "                img2[i] = augment(img2[i], use_cache = False)\n",
    "        pred = sess.run(pred_op, feed_dict = {\n",
    "            image1_pl: img1,\n",
    "            image2_pl: img2\n",
    "        })\n",
    "        sim = pred[:,1]\n",
    "        return img1, img2, sim\n",
    "\n",
    "    def show_coins_sim(img1, img2, sim, cols=4):\n",
    "        h  = image_shape[0]\n",
    "        w  = image_shape[1]\n",
    "        w3 = 32\n",
    "        img1 = np.copy(img1.reshape([num*h,w]))\n",
    "        img2 = np.copy(img2.reshape([num*h,w]))\n",
    "        img3 = np.ones([num*h, w3])\n",
    "        for i in range(num):\n",
    "            s = sim[i]\n",
    "            assert(0.<=s<=1.)\n",
    "            img3[i*h:i*h+h] = s\n",
    "        img1[:,0] = 0\n",
    "        img3[:,w3-1] = 0\n",
    "        img3[:,0] = 0\n",
    "        sheet = np.concatenate([img1, img2, img3], axis=1)\n",
    "        sheet[np.arange(0,h*num,h)-1,:] = 0\n",
    "        sheet[np.arange(0,h*num,h)+1,:] = 0\n",
    "        sheet = np.minimum(sheet, 1)\n",
    "        print(' '.join(['%.2f'%s for s in sim]))\n",
    "        print(' '.join(['='*4 if s>.5 else ' '*4 for s in sim]))    \n",
    "        show_images(images=sheet, image_shape=[h, 2*w+w3], cols=cols, rows=num//cols)\n",
    "\n",
    "    def test_similarity(images1, images2, num, use_aug=True):\n",
    "        img1, img2, sim = get_similarity(images1[:num], images2[:num], use_aug)\n",
    "        show_coins_sim(img1, img2, sim)\n",
    "\n",
    "    num = 20\n",
    "    shift = np.random.randint(data_size)\n",
    "    test_similarity(\n",
    "        images1  = np.roll(test_images, shift, axis=0), \n",
    "        images2  = np.roll(test_images, shift, axis=0), \n",
    "        num      = num,\n",
    "        use_aug  = True)\n",
    "    test_similarity(\n",
    "        images1  = np.roll(test_images, shift+1, axis=0), \n",
    "        images2  = np.roll(test_images, shift  , axis=0), \n",
    "        num      = num,\n",
    "        use_aug  = False)\n",
    "\n",
    "    # ============================================================================\n",
    "    # Eval quality\n",
    "    def calc_pos_similarity(ds, num, use_aug=True):\n",
    "        shift = np.random.randint(len(ds))\n",
    "        img1 = np.roll(ds, shift, axis=0)[:num]\n",
    "        img2 = np.roll(ds, shift, axis=0)[:num]\n",
    "        _, _, sim = get_similarity(img1, img2, use_aug)\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def calc_neg_similarity(ds, num, use_aug=True):\n",
    "        shift = np.random.randint(len(ds))\n",
    "        img1 = np.roll(ds, shift+1, axis=0)[:num]\n",
    "        img2 = np.roll(ds, shift  , axis=0)[:num]\n",
    "        _, i_, sim = get_similarity(img1, img2, use_aug)\n",
    "        return sim\n",
    "\n",
    "    def show_quality(pos_sim, neg_sim):\n",
    "        print(\"Data size          :\", len(pos_sim))\n",
    "        print(\"Mean positive similarity: %.1f%%\" % (np.mean(pos_sim)*100))\n",
    "        print(\"Mean negative similarity: %.1f%%\" % (np.mean(neg_sim)*100))\n",
    "        n = 1000\n",
    "        x = np.zeros(n)\n",
    "        y = np.zeros(n)\n",
    "        s = 0\n",
    "        for i in range(n):\n",
    "            p = i/n\n",
    "            x[i] = 1 - np.mean(neg_sim < p)\n",
    "            y[i] = np.mean(pos_sim > p)\n",
    "            if i>0:\n",
    "                s += (y[i]+y[i-1])/2 * (x[i-1]-x[i])\n",
    "        plt.plot(x, y)\n",
    "        plt.title(\"Quality trade-off: %.1f%% (area under curve)\" % (s*100))\n",
    "        plt.xlabel(\"False negative\")\n",
    "        plt.ylabel(\"True positive\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    num = min(500, data_size)\n",
    "    show_quality(\n",
    "        pos_sim = calc_pos_similarity(test_images, num, use_aug=True), \n",
    "        neg_sim = calc_neg_similarity(test_images, num, use_aug=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augment():\n",
    "    n = 16\n",
    "    s = np.random.randint(data_size-n)\n",
    "    im1 = np.reshape(train_images[s:s+n], [-1,] + image_shape)\n",
    "    im2 = np.copy(im1)\n",
    "    for i in range(n):\n",
    "        im2[i] = augment(im2[i], use_cache=False, rate=1)\n",
    "    show_images(im1, image_shape[:2], cols=n//2, rows=2)\n",
    "    show_images(im2, image_shape[:2], cols=n//2, rows=2)\n",
    "    \n",
    "def test_batching():\n",
    "    n = 8\n",
    "    im1, im2, t = get_next_batch(n)\n",
    "    print([\"%8d\"%t[i][1] for i in range(len(im1))])\n",
    "    show_images(im1, image_shape[:2], cols=n, rows=1)\n",
    "    show_images(im2, image_shape[:2], cols=n, rows=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
