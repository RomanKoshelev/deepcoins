{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric TSNE implementation\n",
    "https://github.com/kylemcdonald/Parametric-t-SNE/blob/master/Parametric%20t-SNE%20(Keras).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D, beta):\n",
    "    eps = 10e-15\n",
    "\n",
    "    P = np.exp(-D * beta)\n",
    "    sumP = np.sum(P) + eps\n",
    "    H = np.log(sumP) + beta * np.sum(np.multiply(D, P)) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2p(X, u=15, tol=1e-4, print_iter=500, max_tries=50):\n",
    "    n = X.shape[0]                     # number of instances\n",
    "    P = np.zeros((n, n))               # empty probability matrix\n",
    "    beta = np.ones(n)                  # empty precision vector\n",
    "    logU = np.log(u)                   # log of perplexity (= entropy)\n",
    "    \n",
    "    sum_X = np.sum(np.square(X), axis=1)\n",
    "    # note: translating sum_X' from matlab to numpy means using reshape to add a dimension\n",
    "    D = sum_X + sum_X[:,None] + -2 * X.dot(X.T)\n",
    "\n",
    "    for i in range(n):        \n",
    "        # Set minimum and maximum values for precision\n",
    "        betamin = float('-inf')\n",
    "        betamax = float('+inf')\n",
    "        \n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        indices = np.concatenate((np.arange(0, i), np.arange(i + 1, n)))\n",
    "        Di = D[i, indices]\n",
    "        H, thisP = Hbeta(Di, beta[i])\n",
    "        \n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while abs(Hdiff) > tol and tries < max_tries:\n",
    "            \n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i]\n",
    "                if np.isinf(betamax):\n",
    "                    beta[i] *= 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2\n",
    "            else:\n",
    "                betamax = beta[i]\n",
    "                if np.isinf(betamin):\n",
    "                    beta[i] /= 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2\n",
    "            \n",
    "            # Recompute the values\n",
    "            H, thisP = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "        \n",
    "        # Set the final row of P\n",
    "        P[i, indices] = thisP\n",
    "        \n",
    "#    if verbose > 0: \n",
    "#         print('Mean value of sigma: {}'.format(np.mean(np.sqrt(1 / beta))))\n",
    "#         print('Minimum value of sigma: {}'.format(np.min(np.sqrt(1 / beta))))\n",
    "#         print('Maximum value of sigma: {}'.format(np.max(np.sqrt(1 / beta))))\n",
    "    \n",
    "    return P, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_probabilities(samples, batch_size, perplexity=30, tol=1e-5):\n",
    "    print('compute_joint_probabilities')\n",
    "    data_size = samples.shape[0]\n",
    "    bs        = min(batch_size, data_size)\n",
    "    bn        = data_size // bs\n",
    "    p         = np.zeros([bn, bs, bs])\n",
    "    eps       = 10e-15\n",
    "\n",
    "    for i in range(bn):\n",
    "        print('  batch %d ... '%i)\n",
    "        batch = samples[i*bs:(i+1)*bs]\n",
    "        p[i], beta = x2p(batch, perplexity, tol)\n",
    "        p[i][np.isnan(p[i])] = eps\n",
    "        p[i] = (p[i] + p[i].T) / 2\n",
    "        p[i] = p[i] / (p[i].sum()+eps)\n",
    "        p[i] = np.maximum(p[i], np.finfo(p[i].dtype).eps)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_loss(P, batch_size, dims, activations):\n",
    "    d = dims\n",
    "    n = batch_size\n",
    "    v = d - 1.\n",
    "    \n",
    "    eps = 10e-15\n",
    "    sum_act = tf.reduce_sum(tf.square(activations), axis=1)\n",
    "    Q = tf.reshape(sum_act, [-1, 1]) + -2 * tf.matmul(activations, activations, transpose_b=True)\n",
    "    Q = (sum_act + Q) / v\n",
    "    Q = tf.pow(1 + Q, -(v + 1) / 2)\n",
    "    Q *= (1 - tf.eye(n))\n",
    "    Q /= tf.reduce_sum(Q)\n",
    "    Q = tf.maximum(Q, eps)\n",
    "    C = tf.log((P + eps) / (Q + eps))\n",
    "    C = tf.reduce_mean(P * C) * 10000000\n",
    "    return C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
