{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE on Tensorflow\n",
    "\n",
    "https://github.com/despoisj/CoinsDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = 1200 # 3000\n",
    "embed_dim = 3\n",
    "image_shape = [64, 64, 1]\n",
    "image_size = np.prod(image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset(ndata):\n",
    "    ds = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "    return  (\n",
    "        ds.train.images[:ndata],\n",
    "        ds.train.labels[:ndata],\n",
    "        ds.test.images[:ndata],\n",
    "        ds.test.labels[:ndata])\n",
    "\n",
    "def load_image_dataset(path, ndata):\n",
    "    classnum = 1\n",
    "    \n",
    "    images = np.zeros([2*ndata, image_size])\n",
    "    labels = np.zeros([2*ndata, classnum])\n",
    "    files  = os.listdir(path)[:2*ndata]\n",
    "    assert len(files) >= 2*ndata, \"%s %s\" % (len(files), 2*ndata)\n",
    "    \n",
    "    for i,f in enumerate(files):\n",
    "        f = os.path.join(path, f)\n",
    "        img = cv2.imread(f)\n",
    "        w = image_shape[0]\n",
    "        h = image_shape[1]\n",
    "        img = cv2.resize(img, (w,h), interpolation = cv2.INTER_CUBIC).astype('float32')\n",
    "        img = np.max(img, axis=2, keepdims=False)\n",
    "        norm = img.max()+.1\n",
    "        img = img.astype('float32') / norm        \n",
    "        # print(img.shape)\n",
    "        # plt.imshow(img, cmap='gray');\n",
    "        # plt.show()\n",
    "        img = np.reshape(img, image_size)\n",
    "        images[i] = img\n",
    "        labels[i,0] = 1\n",
    "    idx = list(range(2*ndata))\n",
    "    np.random.shuffle(idx)\n",
    "    images = images[idx]\n",
    "    labels = labels[idx]\n",
    "    return (\n",
    "        images[:ndata],\n",
    "        labels[:ndata],\n",
    "        images[ndata:2*ndata],\n",
    "        labels[ndata:2*ndata])\n",
    "\n",
    "def load_stamps_dataset(ndata):\n",
    "    return load_image_dataset(\"/netforge/datasets/common/document_parts/10000/stamp\", ndata)\n",
    "\n",
    "def load_coins_dataset(ndata):\n",
    "    return load_image_dataset(\"/netforge/datasets/private/roman/coins/images\", ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 4096)\n",
      "[64, 64, 1]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_coins_dataset(ndata)\n",
    "print(train_images.shape)\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visual routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotEmbedding3d(embeds, labels, title=None, figsize=[10,10]):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.gca(projection='3d')\n",
    "    colors = [np.argmax(labels[i]) for i in range(len(embeds))]\n",
    "    ax.scatter(*zip(*embeds), c=colors, s=100)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "def PlotEmbeddedDataset3d(images, labels, sess, image_pl, emb_op, npoint=500, title=None, figsize=[10,10]):\n",
    "    embeds = sess.run(embed_op, feed_dict = {image_pl : images})[:npoint]\n",
    "    PlotEmbedding3d(embeds, labels[:npoint], title, figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## t-SNE\n",
    "\n",
    "see: https://github.com/maestrojeong/t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    normalize for 1D array\n",
    "    '''\n",
    "    return array/np.sum(array)\n",
    "\n",
    "def get_entropy(array):\n",
    "    '''\n",
    "    Calculate entropy for 1D array\n",
    "    '''\n",
    "    if np.sum(array) !=1:\n",
    "        array = normalize(array)\n",
    "        \n",
    "    sum_ = 0\n",
    "    length = len(array)\n",
    "    for i in range(length):\n",
    "        if array[i]!=0:\n",
    "            sum_+=array[i]*np.log2(array[i])\n",
    "    return -sum_\n",
    "\n",
    "def get_prob(sigma_1d):\n",
    "    '''\n",
    "    prob[i][j] = p_{j|i}\n",
    "    '''\n",
    "    prob = np.zeros([ndata, ndata])\n",
    "    for i in range(ndata):\n",
    "        for j in range(ndata):\n",
    "            prob[i][j] = np.exp(-sq_dist[i][j]/2/sigma_1d[i]/sigma_1d[i])\n",
    "    \n",
    "    #diagonal should be 0\n",
    "    for i in range(ndata):\n",
    "        prob[i][i] = 0 \n",
    "    \n",
    "    for i in range(ndata):\n",
    "        prob[i] = normalize(prob[i])\n",
    "    \n",
    "    return prob\n",
    "\n",
    "def get_prob_1d(row, sigma):\n",
    "    '''\n",
    "    prob[i][j] = p_{j|i}\n",
    "    return prob[i]\n",
    "    '''\n",
    "    prob = np.zeros(ndata)\n",
    "    for j in range(ndata):\n",
    "        prob[j] = np.exp(-sq_dist[row][j]/2/sigma/sigma)\n",
    "    \n",
    "    #diagonal should be 0\n",
    "    prob[row] = 0 \n",
    "    \n",
    "    return normalize(prob)\n",
    "\n",
    "\n",
    "def get_perp(entropy):\n",
    "    return np.power(2, entropy)\n",
    "\n",
    "def get_shape(tensor):\n",
    "    return tensor.get_shape().as_list()\n",
    "\n",
    "def t_sne_loss(y):\n",
    "    '''\n",
    "    Arg :\n",
    "        y - 2D tensor [ndata, nmap]\n",
    "    '''\n",
    "    ndata, nmap = get_shape(y)\n",
    "    y_tr = tf.transpose(y)\n",
    "    y_mapped = []\n",
    "    for i in range(nmap):\n",
    "        y_mapped.append(tf.transpose([y_tr[i]])-y_tr[i])\n",
    "    y_square = 0\n",
    "    for i in range(nmap):\n",
    "        y_square+= tf.square(y_mapped[i])\n",
    "    y_add = y_square+1\n",
    "    y_div = tf.div(1., y_add)\n",
    "    y_mask = y_div*(1-tf.eye(ndata))\n",
    "    y_sum = tf.reduce_sum(y_mask)\n",
    "    y_normalize = y_mask/y_sum\n",
    "    cost = -tf.reduce_mean(joint_prob*tf.log(clip(y_normalize)))\n",
    "    return cost\n",
    "\n",
    "def clip(x, vmax = 1-1e-10, vmin = 1e-10):\n",
    "    return tf.clip_by_value(x, clip_value_max=vmax, clip_value_min=vmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distances: 100.0% ...\n",
      "Done.\n",
      "CPU times: user 48.1 s, sys: 752 ms, total: 48.9 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq_dist= np.zeros([ndata, ndata])\n",
    "for i in range(ndata):\n",
    "    clear_output(True)\n",
    "    print(\"Computing distances: %.1f%% ...\" % ((i+1)/ndata*100))\n",
    "    for j in range(ndata):\n",
    "        sq_dist[i][j] = np.sum(np.square(train_images[i]-train_images[j]))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sigma: 3.1% ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sigma = np.ones(ndata)\n",
    "\n",
    "max_try  = 2000\n",
    "boundary = 1\n",
    "perp     = 20\n",
    "\n",
    "# TODO: vectorize it by numpy or tensorflow\n",
    "\n",
    "for i in range(ndata):\n",
    "    smax = np.max(sq_dist)\n",
    "    smin = np.min(sq_dist)\n",
    "    cur_perp = get_perp(get_entropy(get_prob_1d(i, sigma[i])))\n",
    "    trial = 0\n",
    "    perp_diff = np.abs(perp - cur_perp)\n",
    "    clear_output(True)\n",
    "    print(\"Computing sigma: %.1f%% ...\" % ((i+1)/ndata*100))\n",
    "    while perp_diff > boundary and trial < max_try:\n",
    "        trial+=1\n",
    "        if perp>cur_perp:\n",
    "            smin = sigma[i]\n",
    "            sigma[i] = (sigma[i]+smax)/2\n",
    "        else: \n",
    "            smax = sigma[i]\n",
    "            sigma[i] = (sigma[i]+smin)/2\n",
    "        cur_perp = get_perp(get_entropy(get_prob_1d(i, sigma[i])))\n",
    "        perp_diff = np.abs(perp - cur_perp)\n",
    "\n",
    "prob = get_prob(sigma)\n",
    "joint_prob = np.zeros((ndata, ndata))\n",
    "for i in range(ndata):\n",
    "    clear_output(True)\n",
    "    print(\"Computing joint probs: %.1f%% ...\" % ((i+1)/ndata*100))\n",
    "    for j in range(ndata):\n",
    "        joint_prob[i][j]=(prob[i][j]+prob[j][i])/2/ndata\n",
    "        \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TF Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(inputs, out_dim):\n",
    "    l = inputs\n",
    "    l = tf.layers.dense(l, units=500, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=1000, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=2000, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=out_dim)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_maxpool(inputs, filters, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu):\n",
    "    l = tf.layers.conv2d(\n",
    "        inputs=inputs,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        activation=tf.nn.relu)\n",
    "    return tf.layers.max_pooling2d(l, pool_size=[2, 2], strides=2)\n",
    "     \n",
    "\n",
    "def ConvNet(inputs, inp_shape, out_dim):\n",
    "    l = tf.reshape(inputs, [-1,] + inp_shape)\n",
    "    l = conv2d_maxpool(l, 16)\n",
    "    l = conv2d_maxpool(l, 32)\n",
    "    l = conv2d_maxpool(l, 64)\n",
    "    l = tf.contrib.layers.flatten(l)\n",
    "    l = tf.layers.dense(l, units=200, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=out_dim)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    image_pl = tf.placeholder(dtype = tf.float32, shape = [ndata, image_size], name = 'image_pl')\n",
    "    embed_op = ConvNet(inputs=image_pl, inp_shape=image_shape, out_dim=embed_dim)\n",
    "    cost = t_sne_loss(embed_op)*10000\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "def plot_embedding(images, labels, npoint, title=None):\n",
    "    PlotEmbeddedDataset3d(images, labels, sess, image_pl, embed_op, npoint, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_steps = 2000\n",
    "log_every = 10\n",
    "\n",
    "cost_tract = []\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "try:\n",
    "    for step in range(train_steps):\n",
    "        b_images = train_images\n",
    "        b_labels = train_labels\n",
    "        \n",
    "        _, c = sess.run([train_op, cost], feed_dict={image_pl : b_images})\n",
    "        cost_tract.append(c)\n",
    "        \n",
    "        if step%log_every == log_every - 1:\n",
    "            clear_output(True)\n",
    "            progress = \"Step: %d/%d [%.0f%%], Cost: %.2e\" % (step+1, train_steps, 100*(step+1)/train_steps, c)\n",
    "            # print(progress)\n",
    "            # plot_embedding(b_images, b_labels, 500, progress)\n",
    "            # plt.show()\n",
    "            plt.plot(cost_tract)\n",
    "            plt.show()            \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "clear_output(True)\n",
    "plot_embedding(b_images, b_labels, 500)\n",
    "plt.show()\n",
    "plt.plot(cost_tract)\n",
    "plt.show()\n",
    "print(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_embedding(train_images, train_labels, 2000, \"Train data\")\n",
    "# plt.show()\n",
    "# plot_embedding(test_images, test_labels, 2000, \"Test data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def database():\n",
    "    embeds = sess.run(embed_op, feed_dict = {image_pl : train_images})\n",
    "    return train_images, embeds, train_labels\n",
    "\n",
    "def targets(num):\n",
    "    idx = list(range(ndata))\n",
    "    np.random.shuffle(idx)\n",
    "    images = test_images[idx]\n",
    "    labels = test_labels[idx]\n",
    "\n",
    "    embeds = sess.run(embed_op, feed_dict = {image_pl : images})\n",
    "    return images[:num], embeds[:num], labels[:num]\n",
    "\n",
    "def test_show_targets_embeds(num):\n",
    "    _, embeds, labels = targets(num)\n",
    "    PlotEmbedding3d(embeds, labels, \"Samples\")\n",
    "    plt.show()\n",
    "\n",
    "def test_show_targets_images(num):\n",
    "    images, _, _ = targets(num)\n",
    "    images = images.reshape([num*image_shape[0],image_shape[1]])\n",
    "    plt.imshow(images, cmap='gray');\n",
    "    plt.show()\n",
    "\n",
    "def label_argmax(labels):\n",
    "    return np.argmax(labels, axis=1)\n",
    "\n",
    "def find_nearest(targets, candidates):\n",
    "    tree = spatial.KDTree(candidates)\n",
    "    results = tree.query(targets)\n",
    "    return results[1], results[0] \n",
    "\n",
    "def test_find_nearest_images(num):\n",
    "    trg_img, trg_emb, trg_lbl = targets(num)\n",
    "    dat_img, dat_emb, dat_lbl = database()\n",
    "\n",
    "    nearests, distances = find_nearest(trg_emb, dat_emb)\n",
    "    trg_lbl = label_argmax(trg_lbl)\n",
    "    res_lbl = label_argmax(dat_lbl[nearests])\n",
    "    res_img = dat_img[nearests]\n",
    "    perf = np.sum(trg_lbl==res_lbl) / num\n",
    "\n",
    "    print(\"Data size:\", ndata, \"x\", embed_dim)\n",
    "    print(\"Targets:\", trg_lbl)\n",
    "    print(\"Results:\", res_lbl)\n",
    "    print(\"Quality = %.0f%%\" % (perf*100))\n",
    "    \n",
    "    img_1 = trg_img.reshape([num*image_shape[0],image_shape[1]])\n",
    "    img_2 = res_img.reshape([num*image_shape[0],image_shape[1]])\n",
    "    sheet = np.concatenate([img_1, img_2], axis=1)\n",
    "    plt.figure(figsize = (60,20))\n",
    "    plt.imshow(sheet, cmap='gray');\n",
    "    plt.show()\n",
    "\n",
    "# test_show_targets_embeds(10)\n",
    "# test_show_targets_images(10)\n",
    "test_find_nearest_images(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
