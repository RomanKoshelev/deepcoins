{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE on Tensorflow\n",
    "initial: https://github.com/maestrojeong/t-SNE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = 3000 # 3000\n",
    "image_shape = [28,28,1]\n",
    "image_size = np.prod(image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "train = {}\n",
    "train['image'] = mnist.train.images[:ndata]\n",
    "train['label'] = mnist.train.labels[:ndata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    normalize for 1D array\n",
    "    '''\n",
    "    return array/np.sum(array)\n",
    "\n",
    "def get_entropy(array):\n",
    "    '''\n",
    "    Calculate entropy for 1D array\n",
    "    '''\n",
    "    if np.sum(array) !=1:\n",
    "        array = normalize(array)\n",
    "        \n",
    "    sum_ = 0\n",
    "    length = len(array)\n",
    "    for i in range(length):\n",
    "        if array[i]!=0:\n",
    "            sum_+=array[i]*np.log2(array[i])\n",
    "    return -sum_\n",
    "\n",
    "def get_prob(sigma_1d):\n",
    "    '''\n",
    "    prob[i][j] = p_{j|i}\n",
    "    '''\n",
    "    prob = np.zeros([ndata, ndata])\n",
    "    for i in range(ndata):\n",
    "        for j in range(ndata):\n",
    "            prob[i][j] = np.exp(-sq_dist[i][j]/2/sigma_1d[i]/sigma_1d[i])\n",
    "    \n",
    "    #diagonal should be 0\n",
    "    for i in range(ndata):\n",
    "        prob[i][i] = 0 \n",
    "    \n",
    "    for i in range(ndata):\n",
    "        prob[i] = normalize(prob[i])\n",
    "    \n",
    "    return prob\n",
    "\n",
    "def get_prob_1d(row, sigma):\n",
    "    '''\n",
    "    prob[i][j] = p_{j|i}\n",
    "    return prob[i]\n",
    "    '''\n",
    "    prob = np.zeros(ndata)\n",
    "    for j in range(ndata):\n",
    "        prob[j] = np.exp(-sq_dist[row][j]/2/sigma/sigma)\n",
    "    \n",
    "    #diagonal should be 0\n",
    "    prob[row] = 0 \n",
    "    \n",
    "    return normalize(prob)\n",
    "\n",
    "\n",
    "def get_perp(entropy):\n",
    "    return np.power(2, entropy)\n",
    "\n",
    "def get_shape(tensor):\n",
    "    return tensor.get_shape().as_list()\n",
    "\n",
    "def t_sne(y):\n",
    "    '''\n",
    "    Arg :\n",
    "        y - 2D tensor [ndata, nmap]\n",
    "    '''\n",
    "    batch, nmap = get_shape(y)\n",
    "    y_tr = tf.transpose(y)\n",
    "    y_mapped = []\n",
    "    for i in range(nmap):\n",
    "        y_mapped.append(tf.transpose([y_tr[i]])-y_tr[i])\n",
    "    y_square = 0\n",
    "    for i in range(nmap):\n",
    "        y_square+= tf.square(y_mapped[i])\n",
    "    y_add = y_square+1\n",
    "    y_div = tf.div(1., y_add)\n",
    "    y_mask = y_div*(1-tf.eye(batch))\n",
    "    y_sum = tf.reduce_sum(y_mask)\n",
    "    y_normalize = y_mask/y_sum\n",
    "    cost = -tf.reduce_mean(joint_prob*tf.log(clip(y_normalize)))\n",
    "    return cost\n",
    "\n",
    "def clip(x, vmax = 1-1e-10, vmin = 1e-10):\n",
    "    return tf.clip_by_value(x, clip_value_max=vmax, clip_value_min=vmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute distance: 100.0% ...\n",
      "Done.\n",
      "CPU times: user 4min 16s, sys: 24 s, total: 4min 40s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq_dist= np.zeros([ndata, ndata])\n",
    "for i in range(ndata):\n",
    "    clear_output(True)\n",
    "    print(\"Compute distance: %.1f%% ...\" % ((i+1)/ndata*100))\n",
    "    for j in range(ndata):\n",
    "        sq_dist[i][j] = np.sum(np.square(train['image'][i]-train['image'][j]))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute sigma: 92.8% ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sigma = np.ones(ndata)\n",
    "\n",
    "max_try = 2000\n",
    "boundary = 1\n",
    "perp = 20\n",
    "\n",
    "for i in range(ndata):\n",
    "    smax = np.max(sq_dist)\n",
    "    smin = np.min(sq_dist)\n",
    "    cur_perp = get_perp(get_entropy(get_prob_1d(i, sigma[i])))\n",
    "    trial = 0\n",
    "    perp_diff = np.abs(perp - cur_perp)\n",
    "    clear_output(True)\n",
    "    print(\"Computing sigma: %.1f%% ...\" % ((i+1)/ndata*100))\n",
    "    while perp_diff > boundary and trial < max_try:\n",
    "        trial+=1\n",
    "        if perp>cur_perp:\n",
    "            smin = sigma[i]\n",
    "            sigma[i] = (sigma[i]+smax)/2\n",
    "        else: \n",
    "            smax = sigma[i]\n",
    "            sigma[i] = (sigma[i]+smin)/2\n",
    "        cur_perp = get_perp(get_entropy(get_prob_1d(i, sigma[i])))\n",
    "        perp_diff = np.abs(perp - cur_perp)\n",
    "\n",
    "print('Computing joint probs ...')\n",
    "prob = get_prob(sigma)\n",
    "joint_prob = np.zeros((ndata, ndata))\n",
    "for i in range(ndata):\n",
    "    for j in range(ndata):\n",
    "        joint_prob[i][j]=(prob[i][j]+prob[j][i])/2/ndata\n",
    "        \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotEmbedding3d(dataset, npoint=500, shift=0, title=None):\n",
    "    mapped = sess.run(embeds, feed_dict = {x : dataset.images[shift:shift+ndata]})\n",
    "    mapped = mapped[:npoint]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    ax = fig.gca(projection='3d')\n",
    "    colors = [np.argmax(dataset.labels[shift+i]) for i in range(len(mapped))]\n",
    "    ax.scatter(*zip(*mapped), c=colors, s=100)\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(inputs, out_dim):\n",
    "    \n",
    "    l = inputs\n",
    "    l = tf.layers.dense(l, units=500, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=1000, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=2000, activation=tf.nn.relu)\n",
    "    l = tf.layers.dense(l, units=out_dim)\n",
    "    \n",
    "    outputs = l\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(inputs, out_dim):\n",
    "        l =  tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "        \n",
    "        l = tf.layers.conv2d(\n",
    "            inputs=l,\n",
    "            filters=16,\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        l = tf.layers.max_pooling2d(l, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        l = tf.layers.conv2d(\n",
    "            inputs=l,\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        l = tf.layers.max_pooling2d(l, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        l = tf.layers.conv2d(\n",
    "            inputs=l,\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        l = tf.layers.max_pooling2d(l, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        l = tf.contrib.layers.flatten(l)\n",
    "        l = tf.layers.dense(l, units=200, activation=tf.nn.relu)\n",
    "        l = tf.layers.dense(l, units=out_dim)\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype = tf.float32, shape = [ndata, image_size], name = 'image')\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    embeds = Perceptron(inputs=x, out_dim=3)\n",
    "cost = t_sne(embeds)*10000\n",
    "run_train = tf.train.AdamOptimizer(3e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_steps = 200\n",
    "log_every = 10\n",
    "\n",
    "cost_tract = []\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "try:\n",
    "    for step in range(train_steps):\n",
    "        _, c = sess.run([run_train, cost], feed_dict={x : train['image']})\n",
    "        cost_tract.append(c)\n",
    "        if step%log_every == log_every - 1:\n",
    "            progress = \"Step: %d/%d, Cost: %.2e\" % (step+1, train_steps, c)\n",
    "            PlotEmbedding3d(mnist.train, title=progress, npoint=500)\n",
    "            clear_output(True)\n",
    "            plt.show()            \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "clear_output(True)\n",
    "PlotEmbedding3d(mnist.train, npoint=500);\n",
    "plt.show()\n",
    "plt.plot(cost_tract)\n",
    "plt.show()\n",
    "print(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotEmbedding3d(mnist.train, 2000, title = \"Train\")\n",
    "plt.show()\n",
    "PlotEmbedding3d(mnist.test, 2000, title = \"Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
